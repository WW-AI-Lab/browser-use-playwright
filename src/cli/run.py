"""è¿è¡Œå·¥ä½œæµå‘½ä»¤"""
import asyncio
import json
import sys
from pathlib import Path
from typing import Any, Dict, List, Optional

import typer
from rich.console import Console
from rich.table import Table
from rich.progress import Progress, SpinnerColumn, TextColumn
from rich.panel import Panel
from rich.json import JSON

from src.core.executor import PlaywrightExecutor, task_manager
from src.core.recorder import WorkflowRecorder
from src.models.workflow import Workflow
from src.models.result import ExecutionStatus
from src.utils.logger import logger

console = Console()


def run_workflow(
    workflow_name: str = typer.Argument(..., help="å·¥ä½œæµåç§°"),
    variables: Optional[str] = typer.Option(None, "--vars", "-v", help="è¾“å…¥å˜é‡JSONå­—ç¬¦ä¸²"),
    variables_file: Optional[Path] = typer.Option(None, "--vars-file", "-f", help="è¾“å…¥å˜é‡JSONæ–‡ä»¶"),
    headless: bool = typer.Option(False, "--headless", help="æ— å¤´æ¨¡å¼è¿è¡Œ"),
    timeout: int = typer.Option(30, "--timeout", "-t", help="è¶…æ—¶æ—¶é—´(ç§’)"),
    output: Optional[Path] = typer.Option(None, "--output", "-o", help="ç»“æœè¾“å‡ºæ–‡ä»¶"),
    show_progress: bool = typer.Option(True, "--progress/--no-progress", help="æ˜¾ç¤ºè¿›åº¦æ¡"),
) -> None:
    """è¿è¡Œå·¥ä½œæµ"""
    
    console.print(f"ğŸš€ å¼€å§‹æ‰§è¡Œå·¥ä½œæµ: [bold cyan]{workflow_name}[/bold cyan]")
    
    try:
        # åŠ è½½å·¥ä½œæµ
        recorder = WorkflowRecorder()
        workflow = recorder.load_workflow(workflow_name)
        
        if not workflow:
            console.print(f"âŒ å·¥ä½œæµä¸å­˜åœ¨: {workflow_name}", style="red")
            raise typer.Exit(1)
        
        # è§£æè¾“å…¥å˜é‡
        input_variables = {}
        
        if variables:
            try:
                input_variables.update(json.loads(variables))
            except json.JSONDecodeError as e:
                console.print(f"âŒ å˜é‡JSONæ ¼å¼é”™è¯¯: {e}", style="red")
                raise typer.Exit(1)
        
        if variables_file:
            try:
                with open(variables_file, 'r', encoding='utf-8') as f:
                    file_vars = json.load(f)
                    input_variables.update(file_vars)
            except (FileNotFoundError, json.JSONDecodeError) as e:
                console.print(f"âŒ å˜é‡æ–‡ä»¶é”™è¯¯: {e}", style="red")
                raise typer.Exit(1)
        
        # æ˜¾ç¤ºæ‰§è¡Œä¿¡æ¯
        info_table = Table(title="æ‰§è¡Œä¿¡æ¯")
        info_table.add_column("é¡¹ç›®", style="cyan")
        info_table.add_column("å€¼", style="green")
        
        info_table.add_row("å·¥ä½œæµåç§°", workflow_name)
        info_table.add_row("æ­¥éª¤æ•°é‡", str(len(workflow.steps)))
        info_table.add_row("å˜é‡æ•°é‡", str(len(workflow.variables)))
        info_table.add_row("è¾“å…¥å˜é‡", str(len(input_variables)))
        info_table.add_row("æ— å¤´æ¨¡å¼", "æ˜¯" if headless else "å¦")
        info_table.add_row("è¶…æ—¶æ—¶é—´", f"{timeout}ç§’")
        
        console.print(info_table)
        
        # éªŒè¯å¿…éœ€å˜é‡
        missing_vars = []
        for var_name, var_def in workflow.variables.items():
            if var_def.required and var_name not in input_variables:
                if var_def.default is None:
                    missing_vars.append(var_name)
        
        if missing_vars:
            console.print(f"âŒ ç¼ºå°‘å¿…éœ€å˜é‡: {', '.join(missing_vars)}", style="red")
            raise typer.Exit(1)
        
        # æ‰§è¡Œå·¥ä½œæµ
        console.print("\nğŸ“‹ å¼€å§‹æ‰§è¡Œå·¥ä½œæµ...")
        
        result = asyncio.run(_execute_workflow_async(
            workflow, input_variables, headless, timeout, show_progress
        ))
        
        # æ˜¾ç¤ºæ‰§è¡Œç»“æœ
        _display_execution_result(result)
        
        # ä¿å­˜ç»“æœåˆ°æ–‡ä»¶
        if output:
            _save_result_to_file(result, output)
            console.print(f"ğŸ“„ ç»“æœå·²ä¿å­˜åˆ°: {output}")
        
        # æ ¹æ®æ‰§è¡Œç»“æœè®¾ç½®é€€å‡ºç 
        if result.is_successful:
            console.print("âœ… å·¥ä½œæµæ‰§è¡ŒæˆåŠŸ!", style="green")
        else:
            console.print("âŒ å·¥ä½œæµæ‰§è¡Œå¤±è´¥!", style="red")
            raise typer.Exit(1)
            
    except Exception as e:
        logger.error("æ‰§è¡Œå·¥ä½œæµæ—¶å‡ºé”™", error=str(e))
        console.print(f"âŒ æ‰§è¡Œå¤±è´¥: {e}", style="red")
        raise typer.Exit(1)


def batch_run(
    workflow_name: str = typer.Argument(..., help="å·¥ä½œæµåç§°"),
    data_file: Path = typer.Argument(..., help="æ‰¹é‡æ•°æ®æ–‡ä»¶(JSON)"),
    concurrent: int = typer.Option(5, "--concurrent", "-c", help="å¹¶å‘æ•°é‡"),
    headless: bool = typer.Option(True, "--headless/--no-headless", help="æ— å¤´æ¨¡å¼è¿è¡Œ"),
    timeout: int = typer.Option(30, "--timeout", "-t", help="è¶…æ—¶æ—¶é—´(ç§’)"),
    output_dir: Optional[Path] = typer.Option(None, "--output-dir", "-o", help="ç»“æœè¾“å‡ºç›®å½•"),
    continue_on_error: bool = typer.Option(True, "--continue-on-error/--stop-on-error", help="é‡åˆ°é”™è¯¯æ˜¯å¦ç»§ç»­"),
) -> None:
    """æ‰¹é‡è¿è¡Œå·¥ä½œæµ"""
    
    console.print(f"ğŸš€ å¼€å§‹æ‰¹é‡æ‰§è¡Œå·¥ä½œæµ: [bold cyan]{workflow_name}[/bold cyan]")
    
    try:
        # åŠ è½½å·¥ä½œæµ
        recorder = WorkflowRecorder()
        workflow = recorder.load_workflow(workflow_name)
        
        if not workflow:
            console.print(f"âŒ å·¥ä½œæµä¸å­˜åœ¨: {workflow_name}", style="red")
            raise typer.Exit(1)
        
        # åŠ è½½æ‰¹é‡æ•°æ®
        if not data_file.exists():
            console.print(f"âŒ æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {data_file}", style="red")
            raise typer.Exit(1)
        
        try:
            with open(data_file, 'r', encoding='utf-8') as f:
                input_data_list = json.load(f)
        except json.JSONDecodeError as e:
            console.print(f"âŒ æ•°æ®æ–‡ä»¶JSONæ ¼å¼é”™è¯¯: {e}", style="red")
            raise typer.Exit(1)
        
        if not isinstance(input_data_list, list):
            console.print("âŒ æ•°æ®æ–‡ä»¶å¿…é¡»åŒ…å«JSONæ•°ç»„", style="red")
            raise typer.Exit(1)
        
        # æ˜¾ç¤ºæ‰¹é‡æ‰§è¡Œä¿¡æ¯
        info_table = Table(title="æ‰¹é‡æ‰§è¡Œä¿¡æ¯")
        info_table.add_column("é¡¹ç›®", style="cyan")
        info_table.add_column("å€¼", style="green")
        
        info_table.add_row("å·¥ä½œæµåç§°", workflow_name)
        info_table.add_row("æ•°æ®æ¡æ•°", str(len(input_data_list)))
        info_table.add_row("å¹¶å‘æ•°é‡", str(concurrent))
        info_table.add_row("æ— å¤´æ¨¡å¼", "æ˜¯" if headless else "å¦")
        info_table.add_row("è¶…æ—¶æ—¶é—´", f"{timeout}ç§’")
        
        console.print(info_table)
        
        # æ‰§è¡Œæ‰¹é‡ä»»åŠ¡
        console.print("\nğŸ“‹ å¼€å§‹æ‰¹é‡æ‰§è¡Œ...")
        
        batch_result = asyncio.run(_execute_batch_async(
            workflow, input_data_list, concurrent, headless, timeout
        ))
        
        # æ˜¾ç¤ºæ‰¹é‡æ‰§è¡Œç»“æœ
        _display_batch_result(batch_result)
        
        # ä¿å­˜ç»“æœåˆ°ç›®å½•
        if output_dir:
            _save_batch_results(batch_result, output_dir)
            console.print(f"ğŸ“ æ‰¹é‡ç»“æœå·²ä¿å­˜åˆ°: {output_dir}")
        
        # æ ¹æ®æ‰§è¡Œç»“æœè®¾ç½®é€€å‡ºç 
        if batch_result.success_rate > 0.5:  # æˆåŠŸç‡è¶…è¿‡50%ç®—æˆåŠŸ
            console.print(f"âœ… æ‰¹é‡æ‰§è¡Œå®Œæˆ! æˆåŠŸç‡: {batch_result.success_rate:.1%}", style="green")
        else:
            console.print(f"âŒ æ‰¹é‡æ‰§è¡Œå¤±è´¥! æˆåŠŸç‡: {batch_result.success_rate:.1%}", style="red")
            if not continue_on_error:
                raise typer.Exit(1)
            
    except Exception as e:
        logger.error("æ‰¹é‡æ‰§è¡Œå·¥ä½œæµæ—¶å‡ºé”™", error=str(e))
        console.print(f"âŒ æ‰¹é‡æ‰§è¡Œå¤±è´¥: {e}", style="red")
        raise typer.Exit(1)


def list_tasks() -> None:
    """åˆ—å‡ºæ­£åœ¨è¿è¡Œçš„ä»»åŠ¡"""
    
    console.print("ğŸ“‹ æ­£åœ¨è¿è¡Œçš„ä»»åŠ¡:")
    
    active_tasks = task_manager.get_active_tasks()
    
    if not active_tasks:
        console.print("æ²¡æœ‰æ­£åœ¨è¿è¡Œçš„ä»»åŠ¡", style="yellow")
        return
    
    table = Table()
    table.add_column("ä»»åŠ¡ID", style="cyan")
    table.add_column("å·¥ä½œæµ", style="green")
    table.add_column("çŠ¶æ€", style="yellow")
    table.add_column("å¼€å§‹æ—¶é—´", style="blue")
    table.add_column("æ‰¹æ¬¡å¤§å°", style="magenta")
    
    for task_id, info in active_tasks.items():
        batch_size = str(info.get('batch_size', '-'))
        table.add_row(
            task_id,
            info['workflow_name'],
            info['status'],
            info['start_time'].strftime('%H:%M:%S'),
            batch_size
        )
    
    console.print(table)


async def _execute_workflow_async(
    workflow: Workflow,
    input_variables: Dict[str, Any],
    headless: bool,
    timeout: int,
    show_progress: bool
) -> Any:
    """å¼‚æ­¥æ‰§è¡Œå·¥ä½œæµ"""
    
    executor = PlaywrightExecutor(
        headless=headless,
        timeout=timeout
    )
    
    try:
        if show_progress:
            with Progress(
                SpinnerColumn(),
                TextColumn("[progress.description]{task.description}"),
                console=console,
                transient=True
            ) as progress:
                task = progress.add_task("æ‰§è¡Œå·¥ä½œæµ...", total=None)
                
                result = await executor.execute_workflow(workflow, input_variables)
                
                progress.update(task, description="æ‰§è¡Œå®Œæˆ")
                
                return result
        else:
            return await executor.execute_workflow(workflow, input_variables)
            
    finally:
        await executor.cleanup()


async def _execute_batch_async(
    workflow: Workflow,
    input_data_list: List[Dict[str, Any]],
    concurrent: int,
    headless: bool,
    timeout: int
) -> Any:
    """å¼‚æ­¥æ‰¹é‡æ‰§è¡Œå·¥ä½œæµ"""
    
    executor = PlaywrightExecutor(
        headless=headless,
        timeout=timeout
    )
    
    try:
        with Progress(
            SpinnerColumn(),
            TextColumn("[progress.description]{task.description}"),
            console=console,
            transient=True
        ) as progress:
            task = progress.add_task(f"æ‰¹é‡æ‰§è¡Œ {len(input_data_list)} ä¸ªä»»åŠ¡...", total=None)
            
            result = await executor.execute_batch(
                workflow, input_data_list, concurrent
            )
            
            progress.update(task, description="æ‰¹é‡æ‰§è¡Œå®Œæˆ")
            
            return result
            
    finally:
        await executor.cleanup()


def _display_execution_result(result) -> None:
    """æ˜¾ç¤ºæ‰§è¡Œç»“æœ"""
    
    # åŸºæœ¬ä¿¡æ¯
    status_color = "green" if result.is_successful else "red"
    status_icon = "âœ…" if result.is_successful else "âŒ"
    
    console.print(f"\n{status_icon} æ‰§è¡ŒçŠ¶æ€: [{status_color}]{result.status.value}[/{status_color}]")
    console.print(f"â±ï¸  æ‰§è¡Œæ—¶é•¿: {result.duration:.2f}ç§’")
    console.print(f"ğŸ“Š æˆåŠŸç‡: {result.success_rate:.1%}")
    
    # æ­¥éª¤ç»“æœè¡¨æ ¼
    if result.step_results:
        table = Table(title="æ­¥éª¤æ‰§è¡Œç»“æœ")
        table.add_column("æ­¥éª¤", style="cyan")
        table.add_column("ç±»å‹", style="blue")
        table.add_column("çŠ¶æ€", style="yellow")
        table.add_column("æ—¶é•¿(ç§’)", style="magenta")
        table.add_column("é”™è¯¯", style="red")
        
        for i, step_result in enumerate(result.step_results, 1):
            status_style = "green" if step_result.is_successful else "red"
            duration = f"{step_result.duration:.2f}" if step_result.duration else "-"
            error = step_result.error_message[:50] + "..." if step_result.error_message and len(step_result.error_message) > 50 else (step_result.error_message or "-")
            
            table.add_row(
                str(i),
                step_result.step_type,
                f"[{status_style}]{step_result.status.value}[/{status_style}]",
                duration,
                error
            )
        
        console.print(table)
    
    # è¾“å‡ºå˜é‡
    if result.output_variables:
        console.print("\nğŸ“¤ è¾“å‡ºå˜é‡:")
        console.print(JSON.from_data(result.output_variables))


def _display_batch_result(batch_result) -> None:
    """æ˜¾ç¤ºæ‰¹é‡æ‰§è¡Œç»“æœ"""
    
    # åŸºæœ¬ä¿¡æ¯
    status_color = "green" if batch_result.success_rate > 0.5 else "red"
    
    console.print(f"\nğŸ“Š æ‰¹é‡æ‰§è¡Œç»Ÿè®¡:")
    console.print(f"æ€»ä»»åŠ¡æ•°: {batch_result.total_executions}")
    console.print(f"æˆåŠŸä»»åŠ¡: {batch_result.successful_executions}")
    console.print(f"å¤±è´¥ä»»åŠ¡: {batch_result.failed_executions}")
    console.print(f"[{status_color}]æˆåŠŸç‡: {batch_result.success_rate:.1%}[/{status_color}]")
    console.print(f"â±ï¸  æ€»æ—¶é•¿: {batch_result.duration:.2f}ç§’")
    
    # å¤±è´¥ä»»åŠ¡è¯¦æƒ…
    failed_results = [r for r in batch_result.execution_results if not r.is_successful]
    if failed_results:
        console.print(f"\nâŒ å¤±è´¥ä»»åŠ¡è¯¦æƒ… ({len(failed_results)}ä¸ª):")
        
        table = Table()
        table.add_column("æ‰§è¡ŒID", style="cyan")
        table.add_column("é”™è¯¯ä¿¡æ¯", style="red")
        table.add_column("å¤±è´¥æ­¥éª¤", style="yellow")
        
        for result in failed_results[:10]:  # åªæ˜¾ç¤ºå‰10ä¸ªå¤±è´¥ä»»åŠ¡
            table.add_row(
                result.execution_id,
                (result.error_message[:60] + "...") if result.error_message and len(result.error_message) > 60 else (result.error_message or "-"),
                result.failed_step_id or "-"
            )
        
        console.print(table)
        
        if len(failed_results) > 10:
            console.print(f"... è¿˜æœ‰ {len(failed_results) - 10} ä¸ªå¤±è´¥ä»»åŠ¡")


def _save_result_to_file(result, output_path: Path) -> None:
    """ä¿å­˜æ‰§è¡Œç»“æœåˆ°æ–‡ä»¶"""
    output_path.parent.mkdir(parents=True, exist_ok=True)
    
    result_data = result.model_dump()
    
    with open(output_path, 'w', encoding='utf-8') as f:
        json.dump(result_data, f, ensure_ascii=False, indent=2, default=str)


def _save_batch_results(batch_result, output_dir: Path) -> None:
    """ä¿å­˜æ‰¹é‡æ‰§è¡Œç»“æœ"""
    output_dir.mkdir(parents=True, exist_ok=True)
    
    # ä¿å­˜æ€»ç»“æœ
    summary_file = output_dir / "batch_summary.json"
    with open(summary_file, 'w', encoding='utf-8') as f:
        json.dump(batch_result.model_dump(), f, ensure_ascii=False, indent=2, default=str)
    
    # ä¿å­˜å„ä¸ªæ‰§è¡Œç»“æœ
    results_dir = output_dir / "individual_results"
    results_dir.mkdir(exist_ok=True)
    
    for result in batch_result.execution_results:
        result_file = results_dir / f"{result.execution_id}.json"
        with open(result_file, 'w', encoding='utf-8') as f:
            json.dump(result.model_dump(), f, ensure_ascii=False, indent=2, default=str)
